{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"offen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[bitch]' '[bitch]|[hoe]' '[bitch]|$LOC' '[hoe]|[bitch]' '$DATE|[bitch]']\n"
     ]
    }
   ],
   "source": [
    "inputs = df.iloc[:,3:].values\n",
    "outs = df[\"labels\"].values\n",
    "\n",
    "\n",
    "\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "X_new = selector.fit_transform(inputs, outs)\n",
    "cols = selector.get_support(indices=True)\n",
    "selected_patterns = np.take(df.columns.values,[x+3 for x in cols] )\n",
    "print(selected_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new = df.select_dtypes(include='number').drop(\"id\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df_new.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "\n",
    "reduced_matrix = matrix.mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NUM|[bitch]</th>\n",
       "      <th>NUM|[bitch]+NOUN</th>\n",
       "      <th>NUM|[bitch]+NOUN|AUX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.117709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM|[bitch]</th>\n",
       "      <td>0.445058</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM|[bitch]+NOUN</th>\n",
       "      <td>0.053504</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.248452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM|[bitch]+NOUN|AUX</th>\n",
       "      <td>0.110068</td>\n",
       "      <td>0.362030</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        labels       NUM  NUM|[bitch]  NUM|[bitch]+NOUN  \\\n",
       "labels                     NaN       NaN          NaN               NaN   \n",
       "NUM                   0.117709       NaN          NaN               NaN   \n",
       "NUM|[bitch]           0.445058  0.745356          NaN               NaN   \n",
       "NUM|[bitch]+NOUN      0.053504  0.222222     0.248452               NaN   \n",
       "NUM|[bitch]+NOUN|AUX  0.110068  0.362030     0.333333          0.745356   \n",
       "\n",
       "                      NUM|[bitch]+NOUN|AUX  \n",
       "labels                                 NaN  \n",
       "NUM                                    NaN  \n",
       "NUM|[bitch]                            NaN  \n",
       "NUM|[bitch]+NOUN                       NaN  \n",
       "NUM|[bitch]+NOUN|AUX                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_matrix.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [c for c in reduced_matrix.columns if any(reduced_matrix[c] ==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 370)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_new.drop(to_drop, axis=1)\n",
    "df_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reconstructed = df[df_reduced.columns.values]\n",
    "df_reconstructed = df_reconstructed.drop(\"labels\", axis=1)\n",
    "# df_reconstructed[\"id\"] = df['id']\n",
    "# df_reconstructed[\"sentences\"] = df[\"sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[bitch]' '[bitch]|$LOC' '[hoe]|[bitch]' '[get]|[bitch]' '$DATE|[bitch]']\n"
     ]
    }
   ],
   "source": [
    "inputs = df_reconstructed.values\n",
    "outs = df[\"labels\"].values\n",
    "\n",
    "\n",
    "\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "X_new = selector.fit_transform(inputs, outs)\n",
    "cols = selector.get_support(indices=True)\n",
    "selected_patterns = np.take(df_reconstructed.columns.values,[x for x in cols] )\n",
    "print(selected_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "# Create a custom diverging palette\n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=40,\n",
    "                             n=9, center=\"light\", as_cmap=True)\n",
    "\n",
    "_ = sns.heatmap(matrix, center=0, annot=True, \n",
    "                fmt='.2f', square=True, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "collector = {}\n",
    "labels = df['labels']\n",
    "all_cols = df.columns.values[4:]\n",
    "for col in all_cols:\n",
    "    col_selected = df[col]\n",
    "    fscore = precision_recall_fscore_support(labels, col_selected,  average=\"binary\")[2]\n",
    "    collector[col] =  fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_selected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = {k: v for k, v in sorted(collector.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter = list(collector.keys())[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_selected.append(starter)\n",
    "to_drop = [c for c in corr.columns if corr[starter][c] >= 0.8]\n",
    "df_reduced = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26584/1975192939.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[coll] = np.logical_or(df_reduced[coll], df[starter])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_new = pd.DataFrame()\n",
    "new_cols = df_reduced.columns.values[4:]\n",
    "for coll in new_cols:\n",
    "    \n",
    "    df_new[coll] = np.logical_or(df_reduced[coll], df[starter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 101)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_collector = {}\n",
    "for col in new_cols:\n",
    "    col_selected = df_reduced[col]\n",
    "    fscore = precision_recall_fscore_support(labels, col_selected,  average=\"binary\")[2]\n",
    "    new_collector[col] =  fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$PERCENT|[pay]', ['$PERCENT|[pay]'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starter, patterns_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_collector = {k: v for k, v in sorted(new_collector.items(), key=lambda item: item[1])}\n",
    "new_collector\n",
    "next_starter = list(new_collector.keys())[-1]\n",
    "patterns_selected.append(next_starter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[expensive]|[pay]+*+PRON'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_reduced.corr()\n",
    "to_drop = [c for c in corr.columns if corr[next_starter][c] >= 0.8]\n",
    "df_reduced = df_reduced.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[pay]|[expensive]',\n",
       " '[pay]|[expensive]+*+PRON',\n",
       " '[pay]|[expensive]+*+PRON+AUX',\n",
       " '[expensive]|[pay]',\n",
       " '[expensive]|[pay]+*+PRON',\n",
       " '[expensive]|[pay]+*+PRON+AUX']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# define df, columns, true labels\n",
    "def feature_selector(df):\n",
    "\n",
    "    print(f\"==================================Start of Feature Selection===========================================\")\n",
    "    remaining_cols = df.columns.values[4:]\n",
    "    labels = df['labels']\n",
    "    patterns_selected = []\n",
    "    jj = 0\n",
    "    highest_fscore = \"0.0\"\n",
    "    while len(patterns_selected)<10 and len(remaining_cols)>0:\n",
    "        jj += 1\n",
    "        print(f\"Starting iteration {jj} {len(remaining_cols)}\")\n",
    "        #first calculate the fscore\n",
    "        collector = {}\n",
    "        for col in remaining_cols:\n",
    "            col_selected = df[col]\n",
    "            fscore = precision_recall_fscore_support(labels, col_selected,  average=\"binary\")[2]\n",
    "            exists = str(fscore) in collector\n",
    "            if(exists):\n",
    "                collector[str(fscore)].append(col)\n",
    "                \n",
    "            else:\n",
    "                collector[str(fscore)] = [col]\n",
    "        #sort and get a pattern with high fscore\n",
    "        selected_starter_pattern = list(collector.values())[-1]\n",
    "        collector = {k: v for k, v in sorted(collector.items(), key=lambda item: item[0])}\n",
    "        current_fscore = list(collector.keys())[-1]\n",
    "\n",
    "        if(current_fscore>=highest_fscore):\n",
    "            highest_fscore = current_fscore\n",
    "        else:\n",
    "            # print(f\"{highest_fscore} {current_fscore}, {selected_starter_pattern}\")\n",
    "            break\n",
    "        selected_starter_pattern = list(collector.values())[-1]\n",
    "\n",
    "        #Group the correlated ones and pick the shortest\n",
    "        rowss = df[selected_starter_pattern]\n",
    "        correlation = rowss.corr()\n",
    "        correlation.loc[:,:] =  np.tril(correlation, k=-1)\n",
    "        cor = correlation.stack()\n",
    "        ones = cor[cor ==1].reset_index().loc[:,['level_0','level_1']]\n",
    "        ones = ones.query('level_0 not in level_1')\n",
    "        grps = list(ones.groupby('level_0').groups.keys())\n",
    "        colls = []\n",
    "        for i in grps:\n",
    "            groups = ones[ones[\"level_0\"]==i].values\n",
    "            set_maker = []\n",
    "            for patterns in groups:\n",
    "                set_maker += patterns.tolist()\n",
    "            colls.append(sorted(set_maker, key=len)[0])\n",
    "            \n",
    "        for selected_starter_pattern in colls:\n",
    "            patterns_selected.append(selected_starter_pattern)\n",
    "            try:\n",
    "                selected_starter_series = df[selected_starter_pattern][0]\n",
    "                \n",
    "                corr = df.corr()\n",
    "                to_drop = [c for c in corr.columns if corr[selected_starter_pattern][c] >= 0.8] #0.8 chosen at random\n",
    "                df = df.drop(to_drop, axis=1)\n",
    "\n",
    "                #create a new df with combination of current one\n",
    "                remaining_cols = df.columns.values[4:]\n",
    "                for collumn in remaining_cols:\n",
    "                    df[collumn] = np.logical_or(df[collumn], selected_starter_series)\n",
    "            except:\n",
    "                print(\"We already removed \", selected_starter_pattern)\n",
    "            for coll in remaining_cols:\n",
    "                df[coll] = np.logical_or(df[coll], selected_starter_series)\n",
    "        \n",
    "        print(f\"Finishing iteration {jj} {len(remaining_cols)}, --- {patterns_selected}, {highest_fscore}\")\n",
    "    \n",
    "    print(f\"---------------------------Summary---------------------------\")\n",
    "    print(f\"Patterns {patterns_selected}\")\n",
    "    print(f\"Positive examples \\n{df[df['labels']==1]['sentences'].values}\")\n",
    "    print(f\"Negative examples \\n{df[df['labels']==0]['sentences'].values}\")\n",
    "\n",
    "    print(f\"==================================End of Feature Selection===========================================\")\n",
    "    return patterns_selected\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================Start of Feature Selection===========================================\n",
      "Starting iteration 1 896\n",
      "Finishing iteration 1 893, --- ['[hoe]|[bitch]'], 0.8000000000000002\n",
      "Starting iteration 2 893\n",
      "---------------------------Summary---------------------------\n",
      "Patterns ['[hoe]|[bitch]']\n",
      "Positive examples \n",
      "[\"RT LeezyTheWarrior: Can't be letting them messy hoes mess with yo business...\"\n",
      " 'These hoes soo &#127805;&#127936;' 'b_shiznitt fuck you bitch'\n",
      " 'Never tell a bitch that I love her'\n",
      " 'Lmfao but \" we don\\'t talk \" gtfoh &#128514;&#128514; bitch I guessed it! &amp; I was right &#128514;&#128527;'\n",
      " 'Suck my super monkey balls'\n",
      " 'BengyBenFrank niggah follow me back &#128529;'\n",
      " \"RT SortaBad: A boy won the Scripps Spelling Bee by spelling 'knaidel'. Used in a sentence: I'll never get any pussy because I know how to &#8230;\"\n",
      " \"hi_imkadie I wouldn't know cause i don't fuck with these hoes\"\n",
      " 'RT LouieVRee: This bitch feet been through 20 years of slavery '\n",
      " 'RodMarley44 fr 12 was Finna bam a nicca he said yu lucky I jus got a robbery call'\n",
      " '!!!!!!\"__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"'\n",
      " 'red_daddy17 lilJohn_Fnv9 man fck dat tranny.... Juwanna man ass nigga....'\n",
      " 'dont trust a hoe\\nnever trust a hoe'\n",
      " 'Fuck that Dancehall shit, thru that #TWERKTAPE on bitch'\n",
      " \"Dress like a hoe, I'm goin at you like a hoe just like any other nite. Forget Halloween.\"\n",
      " \"&#8220;CiddyP_60: I wouldn't trust a male cheerleader  All cuz .&#8221; Cimarron got one &#128514; &amp; he got ALLLL the bitches\"\n",
      " 'I really committed to fucking with the richest of bitches'\n",
      " \"I gotta big head yah bitch I think it's crown sized\"\n",
      " \"' South Central niggahs really don't be lovin these hoes , these hoes don't be lovin these niggahs &#1041233; . We just be... \"\n",
      " \"RT Tahrell: Now, bitches gonna think just because they're married, they're better than every female that's not. Smh\"\n",
      " 'These groupie bitches wild enough to suck a babies dick'\n",
      " \"RT HennyHeathen: Bitches eat mad beef,drink Henny and do the shmoney dance that's why they pussy always stink\"\n",
      " 'RT skankymunter: Pissed in shower, now checking for yellow legs.'\n",
      " 'Slaw ass team time to start dat bitch ova'\n",
      " \"Laurenlablue11 basically we ain't got room for basic bitches.\"\n",
      " 'So just chill hoe'\n",
      " 'don07052 almost mad a nigguh catch some stacks at lunch, close one'\n",
      " 'But they only talk on twitter bc pussies in real life'\n",
      " 'RT CodeLez: You gotta know the difference between a good girl and good pussy'\n",
      " \"Die twice bitch &#8220;DivaMonRoe2uHoE: Thank you. &#128536; &#8220;07Cannon: DivaMonRoe2uHoE you're the filthiest hoe of all time \"\n",
      " '1SonofYahweh he aint a real nigger, oh my bad a real nigga, but praise the sonsof satan for having not a realnigger qualitaties. Im hating?'\n",
      " \"Look A Y'all Makeup bitches , Lookin like a ghost when ya wake up bitches\"\n",
      " 'I rarely drink so drunk bitches irritate me'\n",
      " 'allsportsbruh literally retarded. You were dropped on your head.'\n",
      " \"&#8220;Quis_2TurntUp: &#8220;1017_Sqquad: Iont got no type&#8221;bad bitches is the only thing that I like &#128111;&#128131;&#128131;&#8221;aye I'm just living life\"\n",
      " 'RobFernau GregAbbott_TX NRA dead babies piled up like trash at a dump Something to be proud of'\n",
      " 'lilmenifee__ ohh bitch i gotta go fck with my girl my second lil family frfr'\n",
      " 'RT PizzaBeforeHoes: Move dat muscle hoe &#128548; \\n\"Tell me watchu mad foe\"&#128170;&#128514; '\n",
      " 'N%a hit the butta slide at the end of that bitch &#128514;'\n",
      " 'Some rednecks just raced down the freeway &gt;_e']\n",
      "Negative examples \n",
      "[\"RT DefendWallSt: ...wow? RT 1SleepingGiant: Whatever! Fuck all those assholes. They're niggers, they all look alike to me.\"\n",
      " 'RT SUCKEDOFF: 3 MOST COMMON WHITE PEOPLE ACTIVITIES:\\n\\n1. Wearing Tapout\\n\\n2. Shooting up schools\\n\\n3. Calling you a nigger on Xbox'\n",
      " 'Hovaa_ #niggerfood #niggerperson #you #are #a #nigger'\n",
      " \"sweetakin Only rich white liberals know what's best for black people. If they don't see that, they're obviously Uncle Toms.\"\n",
      " \"RT bankheist: you're a retard ShawnaCarr99\"\n",
      " 'Vanessa is such a fuckin faggot.'\n",
      " \"RT imDOPE_GetHigh: Whackko man some lame niggah when I find him I'm unfollowing TF out his ass!\"\n",
      " 'Barbod6FCB _cblaze ODDBEAST cracker jack shut the fuck up'\n",
      " 'SweetKixx u see a lame in that pic ofmine due to your infatuation with niggers. Im Hebrew i fite the children of satan in the streets'\n",
      " \"StarkFreeOrDie ...I fuckin' want OUT&gt; I'm tired of this bullshit faggot ass, closet racist, wannabe-commune-without-railroad state&gt; #Cali\"\n",
      " '2 beer queer'\n",
      " \"drboycewatkins1 Coons and monkeys like you disgust me, you minstrel show negro. Crying about shit all the time you're a disgrace everywhere\"\n",
      " 'Fuckkkkk!!! My nig a g tho, he gonna come back'\n",
      " 'THERACISTDOCTOR One less little nigger that would grow up into a big nigger.'\n",
      " 'OG_HARM moetzart duckydynamo look at this nigger ass nigger shit right here'\n",
      " 'Most niccas broke but always n the limelight' 'JadeGreenleaf fag'\n",
      " 'The #south of the US is white trash.' 'dantoomey2 fuck you faggot'\n",
      " \"I'm seeing more &amp; more niggers migrating further up liberty rd... smh\"\n",
      " 'My best friend loves Justin beiber what a fag &#128557;&#128514;&#128557; Cryystalina'\n",
      " 'Why are some people such faggots? Like were you born that way or are you just that big of a douche bag.'\n",
      " 'Fuckin\\' #faggots, man. #science knows these FUCKS can\\'t procreate without the help of \"breeders\" but we treat them #fancy? #sin'\n",
      " 'MarkHalperin WSJopinion BarackObama Anything to trash this black President!!'\n",
      " 'Blackman38Tide lmfao go to bed whitey &#128129;'\n",
      " 'PatriotsOrg Screw the ragheads.'\n",
      " 'S_Roach happy birthday nicca do coon shit in a responsible way.'\n",
      " 'Iont see how some of you niggas fags!!'\n",
      " 'RT NoWomanIsRight: You can be a good girl all you want and those hoes still gonna get us niggas attention from time to time'\n",
      " 'RT Kriegsson: On Nigger Day we honor nigger traditions by not working.'\n",
      " 'Your acting like a spoiled little faggot have fun'\n",
      " 'bellaangeletti no ud still be a fag if I was lolz'\n",
      " 'Roses be red\\nOrchids be bigger \\nDonts tell yo daddy\\nYou fuckin a nigger \\n#VDdie'\n",
      " \"If a spic ever talks to a white person and the white person kills them, it's self defense.\"\n",
      " 'Arbogucci guys not supposed to get their ass sucked queer'\n",
      " 'Fugazi3011 \"leave you beaner retard\"'\n",
      " 'AndrewJBurns1 Tommy_Russell_ homo ass crackers'\n",
      " 'One of my favorite songs. \"There\\'s a man on the shoreline with a white parakeet trying to make his bird go home.\" '\n",
      " 'Apple need to add some colored emoji'\n",
      " 'mandaxll2963 yellow is even better'\n",
      " \"Pepper_Redbone Yankees Mets Exactly by folks who can't favor to get into that lovely old stadium.\"\n",
      " 'RT Giants: Mariano Rivera now has a street outside Yankee Stadium named after him, which Giants have also had similar honors: '\n",
      " 'dabbba Pinchehonkey Far as I can tell coon tracks on the cab door window - tractor was parked by some trees away from home'\n",
      " 'EXPOSED: Jihadi kidnap and murder handbook... and plan to infiltrate British Army and police  via wordpressdotcom'\n",
      " '&#8220;A_Brown_30: Frogger, best game ever&#8221; only cuz You suck at flappy bird'\n",
      " \"Stop Smokin' Bathsalt, Charlie Brown! #rejectedpeanutsspecials\"\n",
      " \"slayerific13 daisymcgarr Like I said.. I might have to check but I'm just not sure bird shot counts as getting shot.\"\n",
      " \"Khloee's new backpack that we colored last night! &#127912; \"\n",
      " \"Flyers4Cup boy I had no idea that was coming. It's called a smartphone. You're horrible at trash talk\"\n",
      " 'simons_lives keep in shape for the ski slopes'\n",
      " 'RT chughes717: TyZebruh trash cans are always demanding new music from the gawd Tyga'\n",
      " 'RT pambesteder: **WOW* according to this tweet by Tarascan68 Obama must have been an Uncle Tom? '\n",
      " \"Some Jihadi posted a bio of the #ISIS boss Mr Awad with excellent sociological info. Can't thank him/her enough for the gift.\"\n",
      " 'I really want a girl to make me some brownies &#128553;&#128557;'\n",
      " '&#8220;lakeshow73: WCCORosen Too bad the optimism I have for the Royals, you don\\'t have for the Twins!! Take those \"Rose(ie) colored glasses off'\n",
      " 'Jihadis circulating a video of the killing by Boko Haram of a Nigerian pilot captured after his helicopter was shoot down'\n",
      " 'elchavaloko pinche panamonos negros me Dan asco'\n",
      " '85 species of birds reported in Chesterfield for the Great Backyard Bird Count. How many in your area? '\n",
      " 'IMNOTMAKINGITUP Hey u just followed me not long ago. Gonna nip that in da bud. like ur bio tho. U know the white devils stole our our'\n",
      " \"&#8220;BestOfAds: Rape? Cannibalism? You Won't Recognize The Original Versions Of These Fairy Tales  man wtf\"\n",
      " \"MillerCoors Thanks for the follow guys! I'm enjoying a cold yellow belly right now.\"\n",
      " \"RT markhoppus: Yes, yes I know all about the FOB reconciliation. IT WAS MY IDEA! You're welcome.\"\n",
      " \"I'm hooked on monkey phonics.\"\n",
      " 'RT gojackets973: WesDurham its the start of another yellow jacket season tonight!!! How about a RT for ALL the Jacket Fans!!! #GTVT1 ...'\n",
      " 'TheLittleFella_ do yourself a favor and ball that up and throw in the trash.'\n",
      " \"RT dsrtvet: FoxNews tjoy7 And I don't have any confidence NONWHATSOEVER in you Barack! You're the sole reason why this country is in thi&#8230;\"\n",
      " 'RT MCGetBizzy: Rise of the planet of the apes '\n",
      " 'Also, it&#8217;s a hiccup to Jihadi propaganda: they portray themselves as the only ones willing to die for their cause.'\n",
      " 'RT SC4K: Getting ready for the annual heart and sole luncheon RenHotels #cle with EricGordon_CEO '\n",
      " \"cheeky lol RT _MELiSA_jay: I want those all black and yellow 95's again... ughh I &#9825; those\"\n",
      " \"That's right I'm making brownies right now &#128526;&#128523;\"]\n",
      "==================================End of Feature Selection===========================================\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"offen.csv\")\n",
    "\n",
    "features = feature_selector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Hence the food is way too pricey for what's offered\\n\",\n",
       "       'I love that for things you order regularly you can establish a standing order and get a 5 % discount ( milk , eggs , etc . ) .',\n",
       "       \"A little expensive but I'll definitely be back time and time again\\n\",\n",
       "       'For the price I paid, I get more with a vist to another fast food competitor.',\n",
       "       \"but they are more expensive than what I've paid in the past and what another shop charges\\n\",\n",
       "       \"For the amenities and $ paid, it's small.\\n\"], dtype=object)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"labels\"]==1]['sentences'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25bcad2c992ed4a2be145129017787896f246deb7396e6b823d462a0062482c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
